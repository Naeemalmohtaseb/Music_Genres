{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b5e08cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded successfully\n",
      "Loading dataset with error handling...\n",
      "‚úÖ Dataset loaded successfully: (551443, 39)\n",
      "Memory usage: 1872.8 MB\n",
      "Columns: 39\n",
      "Sample of column names:\n",
      "['Artist(s)', 'song', 'text', 'Length', 'emotion', 'Genre', 'Album', 'Release Date', 'Key', 'Tempo']\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup and Robust Data Loading\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries loaded successfully\")\n",
    "\n",
    "# Robust CSV loading with error handling\n",
    "print(\"Loading dataset with error handling...\")\n",
    "\n",
    "try:\n",
    "    # Try standard loading first\n",
    "    df = pd.read_csv('spotify_dataset.csv')\n",
    "    print(f\"‚úÖ Dataset loaded successfully: {df.shape}\")\n",
    "except pd.errors.ParserError:\n",
    "    print(\"‚ö†Ô∏è Standard loading failed, trying robust loading...\")\n",
    "    # Use robust loading options\n",
    "    df = pd.read_csv('spotify_dataset.csv', \n",
    "                     on_bad_lines='skip',  # Skip problematic rows\n",
    "                     quoting=1,           # Handle quotes properly\n",
    "                     encoding='utf-8',    # Explicit encoding\n",
    "                     low_memory=False)    # Read entire file at once\n",
    "    print(f\"‚úÖ Dataset loaded with robust method: {df.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Loading failed: {e}\")\n",
    "    # Last resort - load in chunks and concatenate\n",
    "    print(\"Trying chunk loading...\")\n",
    "    chunks = []\n",
    "    chunk_size = 10000\n",
    "    for chunk in pd.read_csv('spotify_dataset.csv', chunksize=chunk_size, on_bad_lines='skip'):\n",
    "        chunks.append(chunk)\n",
    "    df = pd.concat(chunks, ignore_index=True)\n",
    "    print(f\"‚úÖ Dataset loaded via chunks: {df.shape}\")\n",
    "\n",
    "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "print(f\"Columns: {len(df.columns)}\")\n",
    "print(\"Sample of column names:\")\n",
    "print(list(df.columns[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ca27dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genres after consolidation: 31\n",
      "All genres:\n",
      "Genre\n",
      "hip_hop             282653\n",
      "rock                 60016\n",
      "alternative_rock     38149\n",
      "pop                  34649\n",
      "heavy_metal          17436\n",
      "trap                 15326\n",
      "indie_rock           12335\n",
      "metal                 9945\n",
      "other                 8422\n",
      "country               7898\n",
      "folk                  7396\n",
      "punk_rock             7359\n",
      "jazz                  6881\n",
      "soul                  6775\n",
      "indie_pop             5373\n",
      "blues                 5204\n",
      "punk                  4724\n",
      "reggae                3859\n",
      "electronic            3799\n",
      "classical             3302\n",
      "rap                   2517\n",
      "drum_and_bass         2240\n",
      "k_pop                 1279\n",
      "house                 1256\n",
      "funk                   646\n",
      "indie                  578\n",
      "dubstep                483\n",
      "techno                 467\n",
      "latin                  198\n",
      "acoustic               169\n",
      "rnb                    109\n",
      "Name: count, dtype: int64\n",
      "Class balance ratio: 0.0004\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Genre Consolidation (3097 ‚Üí ~30 genres)\n",
    "def consolidate_genres(genre_str):\n",
    "    if pd.isna(genre_str):\n",
    "        return 'other'\n",
    "    \n",
    "    genre_lower = str(genre_str).lower()\n",
    "    \n",
    "    # Hip-hop and rap sub-genres\n",
    "    if 'trap' in genre_lower and ('hip hop' in genre_lower or 'rap' in genre_lower):\n",
    "        return 'trap'\n",
    "    elif 'trap' in genre_lower:\n",
    "        return 'trap'\n",
    "    elif 'hip hop' in genre_lower or 'hip-hop' in genre_lower:\n",
    "        return 'hip_hop'\n",
    "    elif 'rap' in genre_lower:\n",
    "        return 'rap'\n",
    "    \n",
    "    # Rock sub-genres\n",
    "    elif 'heavy metal' in genre_lower or 'death metal' in genre_lower or 'black metal' in genre_lower:\n",
    "        return 'heavy_metal'\n",
    "    elif 'alternative rock' in genre_lower or 'alt rock' in genre_lower:\n",
    "        return 'alternative_rock'\n",
    "    elif 'punk rock' in genre_lower or (('punk' in genre_lower) and ('rock' in genre_lower)):\n",
    "        return 'punk_rock'\n",
    "    elif 'indie rock' in genre_lower:\n",
    "        return 'indie_rock'\n",
    "    elif 'metal' in genre_lower:\n",
    "        return 'metal'\n",
    "    elif 'punk' in genre_lower:\n",
    "        return 'punk'\n",
    "    elif 'rock' in genre_lower:\n",
    "        return 'rock'\n",
    "    \n",
    "    # Pop sub-genres\n",
    "    elif 'indie pop' in genre_lower:\n",
    "        return 'indie_pop'\n",
    "    elif 'k-pop' in genre_lower:\n",
    "        return 'k_pop'\n",
    "    elif 'pop punk' in genre_lower:\n",
    "        return 'pop_punk'\n",
    "    elif 'pop' in genre_lower or 'mainstream' in genre_lower:\n",
    "        return 'pop'\n",
    "    \n",
    "    # Electronic sub-genres\n",
    "    elif 'house' in genre_lower:\n",
    "        return 'house'\n",
    "    elif 'techno' in genre_lower:\n",
    "        return 'techno'\n",
    "    elif 'dubstep' in genre_lower:\n",
    "        return 'dubstep'\n",
    "    elif 'drum and bass' in genre_lower or 'dnb' in genre_lower:\n",
    "        return 'drum_and_bass'\n",
    "    elif 'edm' in genre_lower or 'electronic dance' in genre_lower:\n",
    "        return 'edm'\n",
    "    elif 'electronic' in genre_lower:\n",
    "        return 'electronic'\n",
    "    \n",
    "    # Jazz and blues\n",
    "    elif 'blues' in genre_lower:\n",
    "        return 'blues'\n",
    "    elif 'jazz' in genre_lower:\n",
    "        return 'jazz'\n",
    "    elif 'soul' in genre_lower:\n",
    "        return 'soul'\n",
    "    elif 'funk' in genre_lower:\n",
    "        return 'funk'\n",
    "    \n",
    "    # Folk and indie\n",
    "    elif 'indie folk' in genre_lower:\n",
    "        return 'indie_folk'\n",
    "    elif 'folk' in genre_lower:\n",
    "        return 'folk'\n",
    "    elif 'acoustic' in genre_lower:\n",
    "        return 'acoustic'\n",
    "    elif 'indie' in genre_lower:\n",
    "        return 'indie'\n",
    "    \n",
    "    # Other genres\n",
    "    elif 'r&b' in genre_lower or 'rnb' in genre_lower:\n",
    "        return 'rnb'\n",
    "    elif 'country' in genre_lower:\n",
    "        return 'country'\n",
    "    elif 'reggae' in genre_lower or 'ska' in genre_lower:\n",
    "        return 'reggae'\n",
    "    elif any(word in genre_lower for word in ['classical', 'orchestra', 'instrumental']):\n",
    "        return 'classical'\n",
    "    elif any(word in genre_lower for word in ['latin', 'salsa', 'bachata']):\n",
    "        return 'latin'\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "df['Genre'] = df['Genre'].apply(consolidate_genres)\n",
    "genre_counts = df['Genre'].value_counts()\n",
    "print(f\"Genres after consolidation: {len(genre_counts)}\")\n",
    "print(\"All genres:\")\n",
    "print(genre_counts)\n",
    "print(f\"Class balance ratio: {genre_counts.min()/genre_counts.max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9094f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATASET OVERVIEW ===\n",
      "Shape: (551443, 42)\n",
      "Missing values: 127\n",
      "Memory: 1882.4 MB\n",
      "\n",
      "Numerical features summary:\n",
      "          Tempo  Loudness    Energy  Danceability  Positiveness  Speechiness  \\\n",
      "count  551443.0  551443.0  551443.0      551443.0      551443.0     551443.0   \n",
      "mean      120.5      -8.1      62.7          59.2          47.7         11.7   \n",
      "std        29.2       4.1      22.4          17.5          24.2         12.3   \n",
      "min        31.0     -50.1       0.0           6.0           0.0          2.0   \n",
      "25%        97.0      -9.8      48.0          47.0          28.0          4.0   \n",
      "50%       120.0      -7.2      65.0          60.0          47.0          6.0   \n",
      "75%       140.0      -5.4      80.0          72.0          66.0         15.0   \n",
      "max       200.0       5.0     100.0          99.0         100.0         97.0   \n",
      "\n",
      "       Liveness  Acousticness  Instrumentalness  Popularity  \n",
      "count  551443.0      551443.0          551443.0    551443.0  \n",
      "mean       19.7          25.7               7.2        32.3  \n",
      "std        16.3          29.3              20.6        18.0  \n",
      "min         1.0           0.0               0.0         0.0  \n",
      "25%        10.0           2.0               0.0        20.0  \n",
      "50%        13.0          12.0               0.0        30.0  \n",
      "75%        25.0          43.0               0.0        43.0  \n",
      "max       100.0         100.0             100.0       100.0  \n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Fix Data Types and Basic EDA\n",
    "# Fix loudness\n",
    "df['Loudness'] = pd.to_numeric(df['Loudness (db)'].astype(str).str.replace('db', ''), errors='coerce')\n",
    "\n",
    "# Fix time signature\n",
    "df['Time_sig'] = pd.to_numeric(df['Time signature'].astype(str).str.extract('(\\d+)')[0], errors='coerce')\n",
    "\n",
    "# Convert length to seconds\n",
    "def to_seconds(length_str):\n",
    "    try:\n",
    "        parts = str(length_str).split(':')\n",
    "        return int(parts[0]) * 60 + int(parts[1]) if len(parts) == 2 else np.nan\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "df['Length_sec'] = df['Length'].apply(to_seconds)\n",
    "\n",
    "# Basic stats\n",
    "print(\"=== DATASET OVERVIEW ===\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Missing values: {df.isnull().sum().sum()}\")\n",
    "print(f\"Memory: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "\n",
    "# Quick numerical summary\n",
    "numerical_cols = ['Tempo', 'Loudness', 'Energy', 'Danceability', 'Positiveness', \n",
    "                 'Speechiness', 'Liveness', 'Acousticness', 'Instrumentalness', 'Popularity']\n",
    "print(\"\\nNumerical features summary:\")\n",
    "print(df[numerical_cols].describe().round(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea504078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MEMORY MANAGEMENT ===\n",
      "Original dataset: 551,443 samples\n",
      "Sampled dataset: 99,982 samples\n",
      "Memory reduction: 18.1% of original\n",
      "\n",
      "Genre distribution after sampling:\n",
      "Genre\n",
      "hip_hop             51256\n",
      "rock                10883\n",
      "alternative_rock     6918\n",
      "pop                  6283\n",
      "heavy_metal          3161\n",
      "trap                 2779\n",
      "indie_rock           2236\n",
      "metal                1803\n",
      "other                1527\n",
      "country              1432\n",
      "Name: count, dtype: int64\n",
      "‚úÖ Using sampled data to prevent memory issues\n"
     ]
    }
   ],
   "source": [
    "# Cell 3A: Memory Management - Sample Data for Development\n",
    "print(\"=== MEMORY MANAGEMENT ===\")\n",
    "\n",
    "# Sample data to prevent memory crashes during development\n",
    "SAMPLE_SIZE = 100000  # Use 100K samples instead of 551K\n",
    "\n",
    "# Stratified sampling to maintain genre proportions\n",
    "df_sample = df.groupby('Genre').apply(\n",
    "    lambda x: x.sample(min(len(x), max(1, int(SAMPLE_SIZE * len(x) / len(df)))), random_state=42)\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print(f\"Original dataset: {len(df):,} samples\")\n",
    "print(f\"Sampled dataset: {len(df_sample):,} samples\")\n",
    "print(f\"Memory reduction: {len(df_sample)/len(df)*100:.1f}% of original\")\n",
    "\n",
    "# Check genre distribution after sampling\n",
    "print(\"\\nGenre distribution after sampling:\")\n",
    "print(df_sample['Genre'].value_counts().head(10))\n",
    "\n",
    "# Use sampled data for processing\n",
    "df = df_sample\n",
    "\n",
    "print(\"‚úÖ Using sampled data to prevent memory issues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06c6d263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CREATING LYRIC WORD FEATURES ===\n",
      "Word occurrence in dataset:\n",
      "  word: 12,424 songs (12.4%)\n",
      "  baby: 22,069 songs (22.1%)\n",
      "  gun: 8,319 songs (8.3%)\n",
      "  truck: 2,283 songs (2.3%)\n",
      "  girl: 19,385 songs (19.4%)\n",
      "  money: 14,958 songs (15.0%)\n",
      "  night: 28,197 songs (28.2%)\n",
      "  love: 42,766 songs (42.8%)\n",
      "  dance: 5,860 songs (5.9%)\n",
      "  freedom: 1,425 songs (1.4%)\n",
      "  whiskey: 614 songs (0.6%)\n",
      "  street: 9,831 songs (9.8%)\n",
      "  heart: 23,022 songs (23.0%)\n",
      "  party: 3,943 songs (3.9%)\n",
      "  devil: 3,018 songs (3.0%)\n",
      "  jesus: 2,606 songs (2.6%)\n",
      "‚úÖ Lyric word features created efficiently\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Create Lyric Word Features (Memory Efficient)\n",
    "target_words = ['word', 'baby', 'gun', 'truck', 'girl', 'money', 'night', 'love', \n",
    "                'dance', 'freedom', 'whiskey', 'street', 'heart', 'party', 'devil', 'jesus']\n",
    "\n",
    "print(\"=== CREATING LYRIC WORD FEATURES ===\")\n",
    "\n",
    "# Process lyrics in chunks to save memory\n",
    "lyrics = df['text'].astype(str).str.lower().fillna('')\n",
    "\n",
    "# Create binary features for each word (more memory efficient)\n",
    "for word in target_words:\n",
    "    df[f'has_{word}'] = lyrics.str.contains(word, na=False).astype('int8')  # Use int8 instead of int64\n",
    "\n",
    "# Summary of word occurrences\n",
    "print(\"Word occurrence in dataset:\")\n",
    "for word in target_words:\n",
    "    count = df[f'has_{word}'].sum()\n",
    "    print(f\"  {word}: {count:,} songs ({count/len(df)*100:.1f}%)\")\n",
    "\n",
    "print(\"‚úÖ Lyric word features created efficiently\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd3cac17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FEATURE ENGINEERING ===\n",
      "Total features available: 33\n",
      "Audio features: 12\n",
      "Lyric features: 16\n",
      "Playlist features: 5\n",
      "Using 26 genres with 100+ samples\n",
      "Final dataset size: 99,727 samples\n",
      "Final feature count: 33\n",
      "‚úÖ Feature engineering completed\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Feature Engineering and Selection\n",
    "print(\"=== FEATURE ENGINEERING ===\")\n",
    "\n",
    "# Define all potential features\n",
    "audio_features = ['Tempo', 'Loudness', 'Energy', 'Danceability', 'Positiveness', \n",
    "                 'Speechiness', 'Liveness', 'Acousticness', 'Instrumentalness', 'Popularity']\n",
    "\n",
    "# Add length and time signature if available\n",
    "if 'Length_sec' in df.columns:\n",
    "    audio_features.append('Length_sec')\n",
    "if 'Time_sig' in df.columns:\n",
    "    audio_features.append('Time_sig')\n",
    "\n",
    "# Lyric word features\n",
    "lyric_features = [f'has_{word}' for word in target_words]\n",
    "\n",
    "# Playlist features (convert to binary)\n",
    "playlist_cols = [col for col in df.columns if 'Good for' in col]\n",
    "for col in playlist_cols:\n",
    "    df[f'{col}_binary'] = (df[col] == 1).astype(int)\n",
    "playlist_features = [f'{col}_binary' for col in playlist_cols]\n",
    "\n",
    "# Explicit content\n",
    "if 'Explicit' in df.columns:\n",
    "    df['Explicit_binary'] = df['Explicit'].map({'Yes': 1, 'No': 0}).fillna(0).astype(int)\n",
    "    playlist_features.append('Explicit_binary')\n",
    "\n",
    "# Combine all features\n",
    "all_features = audio_features + lyric_features + playlist_features[:5]  # Limit playlist features\n",
    "\n",
    "# Handle missing values\n",
    "df[all_features] = df[all_features].fillna(df[all_features].median())\n",
    "\n",
    "print(f\"Total features available: {len(all_features)}\")\n",
    "print(f\"Audio features: {len(audio_features)}\")\n",
    "print(f\"Lyric features: {len(lyric_features)}\")\n",
    "print(f\"Playlist features: {len(playlist_features[:5])}\")\n",
    "\n",
    "# Feature selection to get exactly 50 features\n",
    "X_temp = df[all_features]\n",
    "y_temp = df['Genre']\n",
    "\n",
    "# Remove genres with too few samples for stability\n",
    "genre_counts = y_temp.value_counts()\n",
    "valid_genres = genre_counts[genre_counts >= 100].index\n",
    "mask = y_temp.isin(valid_genres)\n",
    "X_temp = X_temp[mask]\n",
    "y_temp = y_temp[mask]\n",
    "\n",
    "print(f\"Using {len(valid_genres)} genres with 100+ samples\")\n",
    "print(f\"Final dataset size: {len(X_temp):,} samples\")\n",
    "\n",
    "# Select top features if we have more than 50\n",
    "if len(all_features) > 50:\n",
    "    selector = SelectKBest(f_classif, k=50)\n",
    "    X_selected = selector.fit_transform(X_temp, y_temp)\n",
    "    selected_features = [all_features[i] for i in selector.get_support(indices=True)]\n",
    "    print(f\"Selected top 50 features using statistical tests\")\n",
    "else:\n",
    "    selected_features = all_features\n",
    "    X_selected = X_temp.values\n",
    "\n",
    "print(f\"Final feature count: {len(selected_features)}\")\n",
    "print(\"‚úÖ Feature engineering completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "643d7eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== HANDLING CLASS IMBALANCE ===\n",
      "Features selected: 38\n",
      "Dataset shape: (99982, 38)\n",
      "After balancing: (36005, 38)\n",
      "Final genre distribution:\n",
      "Genre\n",
      "hip_hop             3000\n",
      "rock                3000\n",
      "alternative_rock    3000\n",
      "pop                 3000\n",
      "heavy_metal         3000\n",
      "trap                2779\n",
      "indie_rock          2236\n",
      "metal               1803\n",
      "other               1527\n",
      "country             1432\n",
      "folk                1341\n",
      "punk_rock           1334\n",
      "jazz                1247\n",
      "soul                1228\n",
      "indie_pop            974\n",
      "blues                943\n",
      "punk                 856\n",
      "reggae               699\n",
      "electronic           688\n",
      "classical            598\n",
      "rap                  456\n",
      "drum_and_bass        406\n",
      "k_pop                231\n",
      "house                227\n",
      "Name: count, dtype: int64\n",
      "‚úÖ Class imbalance handled\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Handle Class Imbalance with Smart Sampling\n",
    "print(\"=== HANDLING CLASS IMBALANCE ===\")\n",
    "\n",
    "# Prepare features and target\n",
    "feature_cols = [col for col in df.columns if col.startswith('has_') or col in [\n",
    "    'Tempo', 'Loudness', 'Energy', 'Danceability', 'Positiveness', 'Speechiness', \n",
    "    'Liveness', 'Acousticness', 'Instrumentalness', 'Popularity', 'Length_sec', 'Time_sig'\n",
    "] + [col for col in df.columns if 'Good for' in col and 'binary' in col] + ['Explicit_binary']]\n",
    "\n",
    "# Filter to existing columns\n",
    "feature_cols = [col for col in feature_cols if col in df.columns]\n",
    "X = df[feature_cols].fillna(df[feature_cols].median())\n",
    "y = df['Genre']\n",
    "\n",
    "print(f\"Features selected: {len(feature_cols)}\")\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "\n",
    "# Balance classes - cap at 3000 samples per genre, minimum 200\n",
    "from sklearn.utils import resample\n",
    "\n",
    "balanced_dfs = []\n",
    "for genre in y.value_counts().index:\n",
    "    genre_mask = y == genre\n",
    "    genre_X = X[genre_mask]\n",
    "    genre_y = y[genre_mask]\n",
    "    \n",
    "    n_samples = len(genre_y)\n",
    "    \n",
    "    if n_samples > 3000:\n",
    "        # Downsample large genres\n",
    "        X_balanced, y_balanced = resample(genre_X, genre_y, n_samples=3000, random_state=42)\n",
    "    elif n_samples < 200:\n",
    "        # Skip very small genres\n",
    "        continue\n",
    "    else:\n",
    "        X_balanced, y_balanced = genre_X, genre_y\n",
    "    \n",
    "    balanced_df = pd.concat([X_balanced, y_balanced], axis=1)\n",
    "    balanced_dfs.append(balanced_df)\n",
    "\n",
    "# Combine balanced data\n",
    "balanced_data = pd.concat(balanced_dfs, ignore_index=True)\n",
    "X_balanced = balanced_data[feature_cols]\n",
    "y_balanced = balanced_data['Genre']\n",
    "\n",
    "print(f\"After balancing: {X_balanced.shape}\")\n",
    "print(\"Final genre distribution:\")\n",
    "print(y_balanced.value_counts().sort_values(ascending=False))\n",
    "\n",
    "print(\"‚úÖ Class imbalance handled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd8742f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRAIN-TEST SPLIT AND SCALING ===\n",
      "Training set: (28804, 38)\n",
      "Test set: (7201, 38)\n",
      "‚úÖ Data split and scaled\n",
      "Training classes: 24\n",
      "Feature means after scaling: -0.000000\n",
      "Feature stds after scaling: 1.000017\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Train-Test Split and Feature Scaling\n",
    "print(\"=== TRAIN-TEST SPLIT AND SCALING ===\")\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_balanced, y_balanced, test_size=0.2, random_state=42, stratify=y_balanced\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert back to DataFrames for easier handling\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "print(\"‚úÖ Data split and scaled\")\n",
    "print(f\"Training classes: {len(y_train.unique())}\")\n",
    "print(f\"Feature means after scaling: {X_train_scaled.mean().mean():.6f}\")\n",
    "print(f\"Feature stds after scaling: {X_train_scaled.std().mean():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be6f3741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MODEL TRAINING AND EVALUATION ===\n",
      "\n",
      "Training Random Forest...\n",
      "  CV Accuracy: 0.3834 ¬± 0.0025\n",
      "  Test Accuracy: 0.4022\n",
      "\n",
      "Training Gradient Boosting...\n",
      "  CV Accuracy: 0.3099 ¬± 0.0039\n",
      "  Test Accuracy: 0.3183\n",
      "\n",
      "Training Logistic Regression...\n",
      "  CV Accuracy: 0.2568 ¬± 0.0054\n",
      "  Test Accuracy: 0.2612\n",
      "\n",
      "üèÜ Best Model: Random Forest\n",
      "Best Test Accuracy: 0.4022\n",
      "‚úÖ Model training completed\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Model Training with Cross-Validation\n",
    "print(\"=== MODEL TRAINING AND EVALUATION ===\")\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000)\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Use scaled data for Logistic Regression, original for tree-based\n",
    "    if name == 'Logistic Regression':\n",
    "        X_train_use = X_train_scaled\n",
    "        X_test_use = X_test_scaled\n",
    "    else:\n",
    "        X_train_use = X_train\n",
    "        X_test_use = X_test\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train_use, y_train)\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train_use, y_train, cv=5, scoring='accuracy')\n",
    "    \n",
    "    # Test predictions\n",
    "    y_pred = model.predict(X_test_use)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'cv_mean': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std(),\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'predictions': y_pred\n",
    "    }\n",
    "    \n",
    "    print(f\"  CV Accuracy: {cv_scores.mean():.4f} ¬± {cv_scores.std():.4f}\")\n",
    "    print(f\"  Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Find best model\n",
    "best_model_name = max(results.keys(), key=lambda x: results[x]['test_accuracy'])\n",
    "print(f\"\\nüèÜ Best Model: {best_model_name}\")\n",
    "print(f\"Best Test Accuracy: {results[best_model_name]['test_accuracy']:.4f}\")\n",
    "\n",
    "print(\"‚úÖ Model training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3de174e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MODEL ANALYSIS AND OVERFITTING DETECTION ===\n",
      "üìä OVERFITTING ANALYSIS:\n",
      "Training Accuracy: 1.0000\n",
      "Test Accuracy: 0.4022\n",
      "Difference: 0.5978\n",
      "‚ö†Ô∏è Potential overfitting detected (>10% gap)\n",
      "\n",
      "üîç TOP 15 MOST IMPORTANT FEATURES:\n",
      "  Length_sec: 0.0886\n",
      "  Loudness: 0.0835\n",
      "  Danceability: 0.0825\n",
      "  Energy: 0.0814\n",
      "  Positiveness: 0.0811\n",
      "  Popularity: 0.0808\n",
      "  Tempo: 0.0784\n",
      "  Acousticness: 0.0715\n",
      "  Liveness: 0.0700\n",
      "  Speechiness: 0.0577\n",
      "  Instrumentalness: 0.0319\n",
      "  Explicit_binary: 0.0215\n",
      "  has_night: 0.0172\n",
      "  has_love: 0.0169\n",
      "  has_heart: 0.0148\n",
      "\n",
      "üìà MODEL COMPARISON:\n",
      "                 Model  CV_Accuracy  Test_Accuracy  Overfitting\n",
      "0        Random Forest       0.3834         0.4022       0.0187\n",
      "1    Gradient Boosting       0.3099         0.3183       0.0084\n",
      "2  Logistic Regression       0.2568         0.2612       0.0044\n",
      "‚úÖ Model analysis completed\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Model Analysis and Overfitting Detection\n",
    "print(\"=== MODEL ANALYSIS AND OVERFITTING DETECTION ===\")\n",
    "\n",
    "# Get best model\n",
    "best_model = results['Random Forest']['model']\n",
    "\n",
    "# Training accuracy to check overfitting\n",
    "train_pred = best_model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, train_pred)\n",
    "\n",
    "print(f\"üìä OVERFITTING ANALYSIS:\")\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy: {results['Random Forest']['test_accuracy']:.4f}\")\n",
    "print(f\"Difference: {train_accuracy - results['Random Forest']['test_accuracy']:.4f}\")\n",
    "\n",
    "if train_accuracy - results['Random Forest']['test_accuracy'] > 0.1:\n",
    "    print(\"‚ö†Ô∏è Potential overfitting detected (>10% gap)\")\n",
    "else:\n",
    "    print(\"‚úÖ No significant overfitting\")\n",
    "\n",
    "# Feature importance analysis\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': best_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nüîç TOP 15 MOST IMPORTANT FEATURES:\")\n",
    "for i, row in feature_importance.head(15).iterrows():\n",
    "    print(f\"  {row['feature']}: {row['importance']:.4f}\")\n",
    "\n",
    "# Model comparison table\n",
    "print(f\"\\nüìà MODEL COMPARISON:\")\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': list(results.keys()),\n",
    "    'CV_Accuracy': [results[model]['cv_mean'] for model in results.keys()],\n",
    "    'Test_Accuracy': [results[model]['test_accuracy'] for model in results.keys()],\n",
    "    'Overfitting': [results[model]['test_accuracy'] - results[model]['cv_mean'] for model in results.keys()]\n",
    "})\n",
    "print(comparison_df.round(4))\n",
    "\n",
    "print(\"‚úÖ Model analysis completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a024a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PERFORMANCE BY GENRE ===\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "alternative_rock       0.36      0.44      0.40       600\n",
      "           blues       0.70      0.38      0.49       189\n",
      "       classical       0.61      0.09      0.16       120\n",
      "         country       0.30      0.26      0.28       286\n",
      "   drum_and_bass       0.96      0.68      0.80        81\n",
      "      electronic       0.32      0.10      0.15       138\n",
      "            folk       0.27      0.29      0.28       268\n",
      "     heavy_metal       0.56      0.74      0.64       600\n",
      "         hip_hop       0.29      0.30      0.30       600\n",
      "           house       0.75      0.07      0.12        45\n",
      "       indie_pop       0.34      0.05      0.09       195\n",
      "      indie_rock       0.23      0.30      0.26       447\n",
      "            jazz       0.50      0.20      0.28       249\n",
      "           k_pop       0.77      0.43      0.56        46\n",
      "           metal       0.42      0.43      0.42       361\n",
      "           other       0.33      0.10      0.15       305\n",
      "             pop       0.37      0.58      0.45       600\n",
      "            punk       0.35      0.05      0.08       171\n",
      "       punk_rock       0.35      0.30      0.32       267\n",
      "             rap       0.55      0.18      0.27        91\n",
      "          reggae       0.57      0.47      0.52       140\n",
      "            rock       0.33      0.46      0.39       600\n",
      "            soul       0.41      0.17      0.24       246\n",
      "            trap       0.56      0.83      0.67       556\n",
      "\n",
      "        accuracy                           0.40      7201\n",
      "       macro avg       0.47      0.33      0.35      7201\n",
      "    weighted avg       0.41      0.40      0.38      7201\n",
      "\n",
      "\n",
      "üéØ GENRE-SPECIFIC PERFORMANCE:\n",
      "Top 10 performing genres:\n",
      "               Genre  Accuracy  Support\n",
      "23              trap     0.833      556\n",
      "7        heavy_metal     0.745      600\n",
      "4      drum_and_bass     0.679       81\n",
      "16               pop     0.578      600\n",
      "20            reggae     0.471      140\n",
      "21              rock     0.460      600\n",
      "0   alternative_rock     0.442      600\n",
      "13             k_pop     0.435       46\n",
      "14             metal     0.432      361\n",
      "1              blues     0.376      189\n",
      "\n",
      "Worst 5 performing genres:\n",
      "        Genre  Accuracy  Support\n",
      "15      other     0.095      305\n",
      "2   classical     0.092      120\n",
      "9       house     0.067       45\n",
      "10  indie_pop     0.051      195\n",
      "17       punk     0.047      171\n",
      "\n",
      "üí° INSIGHTS:\n",
      "Average per-genre accuracy: 0.329\n",
      "Best performing genre: trap (0.833)\n",
      "Most challenging genre: punk (0.047)\n",
      "‚úÖ Genre performance analysis completed\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Performance by Genre Analysis\n",
    "print(\"=== PERFORMANCE BY GENRE ===\")\n",
    "\n",
    "# Get predictions for best model\n",
    "y_pred_best = results['Random Forest']['predictions']\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_best))\n",
    "\n",
    "# Per-genre accuracy\n",
    "genre_performance = []\n",
    "for genre in sorted(y_test.unique()):\n",
    "    genre_mask = y_test == genre\n",
    "    if genre_mask.sum() > 0:\n",
    "        genre_accuracy = accuracy_score(y_test[genre_mask], y_pred_best[genre_mask])\n",
    "        genre_support = genre_mask.sum()\n",
    "        genre_performance.append({\n",
    "            'Genre': genre,\n",
    "            'Accuracy': genre_accuracy,\n",
    "            'Support': genre_support\n",
    "        })\n",
    "\n",
    "genre_df = pd.DataFrame(genre_performance).sort_values('Accuracy', ascending=False)\n",
    "\n",
    "print(f\"\\nüéØ GENRE-SPECIFIC PERFORMANCE:\")\n",
    "print(\"Top 10 performing genres:\")\n",
    "print(genre_df.head(10)[['Genre', 'Accuracy', 'Support']].round(3))\n",
    "\n",
    "print(f\"\\nWorst 5 performing genres:\")\n",
    "print(genre_df.tail(5)[['Genre', 'Accuracy', 'Support']].round(3))\n",
    "\n",
    "# Overall insights\n",
    "avg_accuracy = genre_df['Accuracy'].mean()\n",
    "print(f\"\\nüí° INSIGHTS:\")\n",
    "print(f\"Average per-genre accuracy: {avg_accuracy:.3f}\")\n",
    "print(f\"Best performing genre: {genre_df.iloc[0]['Genre']} ({genre_df.iloc[0]['Accuracy']:.3f})\")\n",
    "print(f\"Most challenging genre: {genre_df.iloc[-1]['Genre']} ({genre_df.iloc[-1]['Accuracy']:.3f})\")\n",
    "\n",
    "print(\"‚úÖ Genre performance analysis completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99a9b40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FEATURE SELECTION AND OPTIMIZATION ===\n",
      "Reducing features from 38 to 28\n",
      "Training optimized Random Forest...\n",
      "\n",
      "üìä OPTIMIZED MODEL RESULTS:\n",
      "CV Accuracy: 0.3654 ¬± 0.0030\n",
      "Train Accuracy: 0.7868\n",
      "Test Accuracy: 0.3841\n",
      "Overfitting Gap: 0.4027\n",
      "\n",
      "üîÑ IMPROVEMENT:\n",
      "Original: 0.4022\n",
      "Optimized: 0.3841\n",
      "Change: -0.0181\n",
      "‚úÖ Feature selection and optimization completed\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Feature Selection and Model Optimization\n",
    "print(\"=== FEATURE SELECTION AND OPTIMIZATION ===\")\n",
    "\n",
    "# Remove low-importance features (bottom 25%)\n",
    "n_features_keep = int(len(feature_importance) * 0.75)  # Keep top 75% of features\n",
    "important_features = feature_importance.head(n_features_keep)['feature'].tolist()\n",
    "\n",
    "print(f\"Reducing features from {len(X_train.columns)} to {len(important_features)}\")\n",
    "\n",
    "# Retrain with selected features\n",
    "X_train_selected = X_train[important_features]\n",
    "X_test_selected = X_test[important_features]\n",
    "\n",
    "# Train optimized Random Forest\n",
    "rf_optimized = RandomForestClassifier(\n",
    "    n_estimators=150,  # Slightly more trees\n",
    "    max_depth=15,      # Limit depth to prevent overfitting\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Training optimized Random Forest...\")\n",
    "rf_optimized.fit(X_train_selected, y_train)\n",
    "\n",
    "# Evaluate optimized model\n",
    "cv_scores_opt = cross_val_score(rf_optimized, X_train_selected, y_train, cv=5)\n",
    "y_pred_opt = rf_optimized.predict(X_test_selected)\n",
    "test_accuracy_opt = accuracy_score(y_test, y_pred_opt)\n",
    "train_accuracy_opt = accuracy_score(y_train, rf_optimized.predict(X_train_selected))\n",
    "\n",
    "print(f\"\\nüìä OPTIMIZED MODEL RESULTS:\")\n",
    "print(f\"CV Accuracy: {cv_scores_opt.mean():.4f} ¬± {cv_scores_opt.std():.4f}\")\n",
    "print(f\"Train Accuracy: {train_accuracy_opt:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy_opt:.4f}\")\n",
    "print(f\"Overfitting Gap: {train_accuracy_opt - test_accuracy_opt:.4f}\")\n",
    "\n",
    "print(f\"\\nüîÑ IMPROVEMENT:\")\n",
    "original_accuracy = results['Random Forest']['test_accuracy']\n",
    "print(f\"Original: {original_accuracy:.4f}\")\n",
    "print(f\"Optimized: {test_accuracy_opt:.4f}\")\n",
    "print(f\"Change: {test_accuracy_opt - original_accuracy:+.4f}\")\n",
    "\n",
    "print(\"‚úÖ Feature selection and optimization completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76779274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ADDRESSING OVERFITTING ===\n",
      "\n",
      "Testing RF_Conservative...\n",
      "  Train Acc: 0.3155\n",
      "  Test Acc: 0.2795\n",
      "  CV Acc: 0.2768\n",
      "  Overfitting Gap: 0.0360\n",
      "\n",
      "Testing RF_VeryConservative...\n",
      "  Train Acc: 0.2453\n",
      "  Test Acc: 0.2344\n",
      "  CV Acc: 0.2358\n",
      "  Overfitting Gap: 0.0109\n",
      "\n",
      "Testing GradientBoosting_Reg...\n",
      "  Train Acc: 0.3699\n",
      "  Test Acc: 0.3072\n",
      "  CV Acc: 0.3024\n",
      "  Overfitting Gap: 0.0628\n",
      "\n",
      "üèÜ Best Regularized Model: RF_Conservative\n",
      "Overfitting Gap: 0.0360\n",
      "Test Accuracy: 0.2795\n",
      "‚úÖ Overfitting mitigation completed\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Address Overfitting with Stronger Regularization\n",
    "print(\"=== ADDRESSING OVERFITTING ===\")\n",
    "\n",
    "# Try multiple regularization strategies\n",
    "models_regularized = {\n",
    "    'RF_Conservative': RandomForestClassifier(\n",
    "        n_estimators=50,        # Fewer trees\n",
    "        max_depth=8,           # Much shallower\n",
    "        min_samples_split=20,   # Require more samples to split\n",
    "        min_samples_leaf=10,    # Larger leaf nodes\n",
    "        max_features='sqrt',    # Fewer features per split\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'RF_VeryConservative': RandomForestClassifier(\n",
    "        n_estimators=30,\n",
    "        max_depth=5,\n",
    "        min_samples_split=50,\n",
    "        min_samples_leaf=20,\n",
    "        max_features=0.3,       # Even fewer features\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'GradientBoosting_Reg': GradientBoostingClassifier(\n",
    "        n_estimators=50,\n",
    "        learning_rate=0.05,     # Slower learning\n",
    "        max_depth=4,\n",
    "        min_samples_split=20,\n",
    "        min_samples_leaf=10,\n",
    "        subsample=0.8,          # Use only 80% of data per tree\n",
    "        random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "# Test regularized models\n",
    "reg_results = {}\n",
    "for name, model in models_regularized.items():\n",
    "    print(f\"\\nTesting {name}...\")\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train_selected, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    train_acc = accuracy_score(y_train, model.predict(X_train_selected))\n",
    "    test_acc = accuracy_score(y_test, model.predict(X_test_selected))\n",
    "    cv_scores = cross_val_score(model, X_train_selected, y_train, cv=5)\n",
    "    \n",
    "    overfitting_gap = train_acc - test_acc\n",
    "    \n",
    "    reg_results[name] = {\n",
    "        'train_acc': train_acc,\n",
    "        'test_acc': test_acc,\n",
    "        'cv_mean': cv_scores.mean(),\n",
    "        'overfitting_gap': overfitting_gap,\n",
    "        'model': model\n",
    "    }\n",
    "    \n",
    "    print(f\"  Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"  Test Acc: {test_acc:.4f}\")\n",
    "    print(f\"  CV Acc: {cv_scores.mean():.4f}\")\n",
    "    print(f\"  Overfitting Gap: {overfitting_gap:.4f}\")\n",
    "\n",
    "# Find best regularized model (lowest overfitting with decent performance)\n",
    "best_reg_model = min(reg_results.keys(), \n",
    "                     key=lambda x: reg_results[x]['overfitting_gap'] if reg_results[x]['test_acc'] > 0.25 else 999)\n",
    "\n",
    "print(f\"\\nüèÜ Best Regularized Model: {best_reg_model}\")\n",
    "print(f\"Overfitting Gap: {reg_results[best_reg_model]['overfitting_gap']:.4f}\")\n",
    "print(f\"Test Accuracy: {reg_results[best_reg_model]['test_acc']:.4f}\")\n",
    "\n",
    "print(\"‚úÖ Overfitting mitigation completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13797214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FINAL MODEL EVALUATION ===\n",
      "Confusion Matrix (Top 8 Genres):\n",
      "Genre             pop  alternative_rock  heavy_metal  rock  hip_hop  trap  \\\n",
      "Genre                                                                       \n",
      "pop               328                34           15    88       47    43   \n",
      "alternative_rock  125               140          111    81       23    23   \n",
      "heavy_metal        38                50          364    43       22    22   \n",
      "rock              184                53           55   202       32    33   \n",
      "hip_hop           130                35           25    43      112   209   \n",
      "trap               24                 7            3     3       29   486   \n",
      "indie_rock         92                75           52    80       26    14   \n",
      "metal              20                25          180     8        6    10   \n",
      "\n",
      "Genre             indie_rock  metal  \n",
      "Genre                                \n",
      "pop                       40      0  \n",
      "alternative_rock          46     37  \n",
      "heavy_metal               23     27  \n",
      "rock                      30      5  \n",
      "hip_hop                   28      6  \n",
      "trap                       2      0  \n",
      "indie_rock                84     10  \n",
      "metal                     13     91  \n",
      "\n",
      "üéØ GENRE CLASSIFICATION INSIGHTS:\n",
      "  trap: 0.874 accuracy (556 samples)\n",
      "  heavy_metal: 0.607 accuracy (600 samples)\n",
      "  pop: 0.547 accuracy (600 samples)\n",
      "  rock: 0.337 accuracy (600 samples)\n",
      "  metal: 0.252 accuracy (361 samples)\n",
      "  alternative_rock: 0.233 accuracy (600 samples)\n",
      "  indie_rock: 0.188 accuracy (447 samples)\n",
      "  hip_hop: 0.187 accuracy (600 samples)\n",
      "\n",
      "üîç FINAL MODEL - TOP 10 FEATURES:\n",
      "  Explicit_binary: 0.1576\n",
      "  Acousticness: 0.1327\n",
      "  Speechiness: 0.1105\n",
      "  Energy: 0.1041\n",
      "  Danceability: 0.0975\n",
      "  Length_sec: 0.0800\n",
      "  Positiveness: 0.0562\n",
      "  Popularity: 0.0490\n",
      "  Loudness: 0.0453\n",
      "  Tempo: 0.0368\n",
      "‚úÖ Final evaluation completed\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: Final Model Evaluation and Insights\n",
    "print(\"=== FINAL MODEL EVALUATION ===\")\n",
    "\n",
    "# Get final model\n",
    "final_model = reg_results[best_reg_model]['model']\n",
    "final_predictions = final_model.predict(X_test_selected)\n",
    "\n",
    "# Confusion matrix for top genres (to avoid clutter)\n",
    "top_genres = y_test.value_counts().head(8).index\n",
    "mask = y_test.isin(top_genres)\n",
    "y_test_top = y_test[mask]\n",
    "y_pred_top = final_predictions[mask]\n",
    "\n",
    "# Create simplified confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test_top, y_pred_top, labels=top_genres)\n",
    "\n",
    "print(\"Confusion Matrix (Top 8 Genres):\")\n",
    "cm_df = pd.DataFrame(cm, index=top_genres, columns=top_genres)\n",
    "print(cm_df)\n",
    "\n",
    "# Genre-specific insights\n",
    "print(f\"\\nüéØ GENRE CLASSIFICATION INSIGHTS:\")\n",
    "genre_insights = []\n",
    "for genre in top_genres:\n",
    "    mask = y_test == genre\n",
    "    if mask.sum() > 20:  # Only genres with sufficient samples\n",
    "        accuracy = accuracy_score(y_test[mask], final_predictions[mask])\n",
    "        genre_insights.append((genre, accuracy, mask.sum()))\n",
    "\n",
    "genre_insights.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for genre, acc, support in genre_insights:\n",
    "    print(f\"  {genre}: {acc:.3f} accuracy ({support} samples)\")\n",
    "\n",
    "# Feature importance from final model\n",
    "final_importance = pd.DataFrame({\n",
    "    'feature': X_train_selected.columns,\n",
    "    'importance': final_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nüîç FINAL MODEL - TOP 10 FEATURES:\")\n",
    "for i, row in final_importance.head(10).iterrows():\n",
    "    print(f\"  {row['feature']}: {row['importance']:.4f}\")\n",
    "\n",
    "print(\"‚úÖ Final evaluation completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42726bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üéµ MUSIC GENRE CLASSIFICATION - FINAL RESULTS\n",
      "============================================================\n",
      "\n",
      "üìä DATASET SUMMARY:\n",
      "‚Ä¢ Original samples: 551,443\n",
      "‚Ä¢ Working samples: 36,005\n",
      "‚Ä¢ Genres classified: 24\n",
      "‚Ä¢ Features used: 28\n",
      "\n",
      "üèÜ BEST MODEL PERFORMANCE:\n",
      "‚Ä¢ Model: RF_Conservative\n",
      "‚Ä¢ Test Accuracy: 0.2795\n",
      "‚Ä¢ Cross-validation: 0.2768\n",
      "‚Ä¢ Overfitting Gap: 0.0360\n",
      "\n",
      "üéØ CLASSIFICATION STRENGTHS:\n",
      "‚Ä¢ Best classified: trap, heavy_metal, pop\n",
      "‚Ä¢ Most challenging: alternative_rock, indie_rock, hip_hop\n",
      "\n",
      "üîç KEY PREDICTIVE FEATURES:\n",
      "‚Ä¢ Audio: ['Explicit_binary', 'Acousticness', 'Speechiness', 'Energy', 'Danceability']\n",
      "‚Ä¢ Lyrical: []\n",
      "\n",
      "üí° INSIGHTS & RECOMMENDATIONS:\n",
      "‚Ä¢ Model works best for distinct genres (trap, heavy_metal, drum_and_bass)\n",
      "‚Ä¢ Similar genres (rock subgenres, pop variants) are harder to distinguish\n",
      "‚Ä¢ Audio features more important than lyrical content\n",
      "‚Ä¢ Length and loudness are surprisingly predictive\n",
      "\n",
      "‚ö° NEXT STEPS:\n",
      "‚Ä¢ Collect more data for underperforming genres\n",
      "‚Ä¢ Consider genre hierarchy (rock ‚Üí subgenres)\n",
      "‚Ä¢ Add more audio features (spectral, rhythm)\n",
      "‚Ä¢ Ensemble multiple models\n",
      "\n",
      "üìà PERFORMANCE vs BASELINE:\n",
      "‚Ä¢ Random chance: 0.0417\n",
      "‚Ä¢ Our model: 0.2795\n",
      "‚Ä¢ Improvement: 6.7x better than random\n",
      "============================================================\n",
      "üéâ ANALYSIS COMPLETE!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 14: Model Summary and Recommendations\n",
    "print(\"=\" * 60)\n",
    "print(\"üéµ MUSIC GENRE CLASSIFICATION - FINAL RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüìä DATASET SUMMARY:\")\n",
    "print(f\"‚Ä¢ Original samples: 551,443\")\n",
    "print(f\"‚Ä¢ Working samples: {len(X_balanced):,}\")\n",
    "print(f\"‚Ä¢ Genres classified: {len(y_test.unique())}\")\n",
    "print(f\"‚Ä¢ Features used: {len(X_train_selected.columns)}\")\n",
    "\n",
    "print(f\"\\nüèÜ BEST MODEL PERFORMANCE:\")\n",
    "print(f\"‚Ä¢ Model: {best_reg_model}\")\n",
    "print(f\"‚Ä¢ Test Accuracy: {reg_results[best_reg_model]['test_acc']:.4f}\")\n",
    "print(f\"‚Ä¢ Cross-validation: {reg_results[best_reg_model]['cv_mean']:.4f}\")\n",
    "print(f\"‚Ä¢ Overfitting Gap: {reg_results[best_reg_model]['overfitting_gap']:.4f}\")\n",
    "\n",
    "print(f\"\\nüéØ CLASSIFICATION STRENGTHS:\")\n",
    "easiest_genres = [g for g, acc, _ in genre_insights[:3]]\n",
    "hardest_genres = [g for g, acc, _ in genre_insights[-3:]]\n",
    "print(f\"‚Ä¢ Best classified: {', '.join(easiest_genres)}\")\n",
    "print(f\"‚Ä¢ Most challenging: {', '.join(hardest_genres)}\")\n",
    "\n",
    "print(f\"\\nüîç KEY PREDICTIVE FEATURES:\")\n",
    "top_5_features = final_importance.head(5)['feature'].tolist()\n",
    "print(f\"‚Ä¢ Audio: {[f for f in top_5_features if not f.startswith('has_')]}\")\n",
    "print(f\"‚Ä¢ Lyrical: {[f for f in top_5_features if f.startswith('has_')]}\")\n",
    "\n",
    "print(f\"\\nüí° INSIGHTS & RECOMMENDATIONS:\")\n",
    "print(f\"‚Ä¢ Model works best for distinct genres (trap, heavy_metal, drum_and_bass)\")\n",
    "print(f\"‚Ä¢ Similar genres (rock subgenres, pop variants) are harder to distinguish\")\n",
    "print(f\"‚Ä¢ Audio features more important than lyrical content\")\n",
    "print(f\"‚Ä¢ Length and loudness are surprisingly predictive\")\n",
    "\n",
    "print(f\"\\n‚ö° NEXT STEPS:\")\n",
    "print(f\"‚Ä¢ Collect more data for underperforming genres\")\n",
    "print(f\"‚Ä¢ Consider genre hierarchy (rock ‚Üí subgenres)\")\n",
    "print(f\"‚Ä¢ Add more audio features (spectral, rhythm)\")\n",
    "print(f\"‚Ä¢ Ensemble multiple models\")\n",
    "\n",
    "baseline_accuracy = 1 / len(y_test.unique())  # Random chance\n",
    "improvement = reg_results[best_reg_model]['test_acc'] / baseline_accuracy\n",
    "\n",
    "print(f\"\\nüìà PERFORMANCE vs BASELINE:\")\n",
    "print(f\"‚Ä¢ Random chance: {baseline_accuracy:.4f}\")\n",
    "print(f\"‚Ä¢ Our model: {reg_results[best_reg_model]['test_acc']:.4f}\")\n",
    "print(f\"‚Ä¢ Improvement: {improvement:.1f}x better than random\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üéâ ANALYSIS COMPLETE!\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
